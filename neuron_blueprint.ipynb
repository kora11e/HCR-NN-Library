{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68b66aa2",
   "metadata": {},
   "source": [
    "<h2>Implementacja modelu HCRNN do postaci Neurona</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a026e",
   "metadata": {},
   "source": [
    "Artykuł naukowy:\n",
    "Instniejace, podobne rozwiązania:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62247169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math, os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334bf9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [\n",
    "    'HCRNN_Neuron'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1705e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "\n",
    "'''\n",
    "Klasa rozszerzająca funkcje torch'a.\n",
    "'''\n",
    "\n",
    "class HCRNN_Neuron(nn.Module):\n",
    "\n",
    "    '''\n",
    "    definicja stałych określająca rozmiar wejścia i wyjścia dla liczb neuronów.\n",
    "    '''\n",
    "\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        \n",
    "        #definicja urządzenia, CPU, GPU lub TPU\n",
    "        device = None,\n",
    "        dtype= None,\n",
    "\n",
    "    ) -> None:\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        super().__init__()\n",
    "\n",
    "    #Tensor wchodzi i zawsze Tensor wychodzi\n",
    "    def forward(self, input:Tensor) -> Tensor:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d07ef1a",
   "metadata": {},
   "source": [
    "<h2>Normalization</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef073368",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mNormalizeLayer\u001b[39;00m(\u001b[43mnn\u001b[49m.Module):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      3\u001b[39m         \u001b[38;5;28mself\u001b[39m.data = data\n",
      "\u001b[31mNameError\u001b[39m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class CDFNorm(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        unbiased: bool = True,\n",
    "        eps: float = 1e-5,\n",
    "        affine: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.unbiased  = unbiased\n",
    "        self.eps       = eps\n",
    "\n",
    "        if affine:\n",
    "            self.weight = nn.Parameter(torch.ones(1))\n",
    "            self.bias   = nn.Parameter(torch.zeros(1))\n",
    "        else:\n",
    "            self.register_parameter(\"weight\", None)\n",
    "            self.register_parameter(\"bias\",   None)\n",
    "\n",
    "    def _empirical_cdf(self, x: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "        sorted_x, _ = torch.sort(x, dim=dim)\n",
    "        idx = torch.searchsorted(sorted_x, x, right=False, dim=dim)\n",
    "        N   = x.size(dim)\n",
    "        return (idx.to(x.dtype) + 0.5) / N\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        stat_dim = 0\n",
    "        \n",
    "        u = self._empirical_cdf(x, stat_dim)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            u = u * self.weight + self.bias\n",
    "        return u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de67962",
   "metadata": {},
   "source": [
    "<h2>Joint Distribution</h2>\n",
    "Rozłożone w dwóch i trzech wymiarach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239ccf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointDistribution3D(nn.Module):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 x:Tensor,\n",
    "                 y:Tensor,\n",
    "                 z:Tensor,\n",
    "                 a:Tensor\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.x = x,\n",
    "        self.y = y,\n",
    "        self.z = z,\n",
    "        self.a = a\n",
    "    \n",
    "    #a = torch.rand((10,2))\n",
    "    #b = torch.rand((10,5))\n",
    "\n",
    "    def computeJointDistribution(self) -> Tensor:\n",
    "        joint = torch.zeros()\n",
    "\n",
    "        for i in range(2):\n",
    "            for j in range(5):\n",
    "                for z in range(5):\n",
    "                    joint[:, i*5+j] = self.x[:, i]*self.y[:, j]*self.z[:, z]\n",
    "\n",
    "        c = self.x.unsqueeze(1) @ self.y.unsqueeze(1) @ self.z.unsqueeze(1)\n",
    "        \n",
    "        torch.reshape(c, self.a.shape)\n",
    "\n",
    "        # sprawdzić wyniki\n",
    "        #print(torch.allclose(a, joint))\n",
    "\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003cd012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointDistribution2D(nn.Module):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 x:Tensor,\n",
    "                 y:Tensor,\n",
    "                 #z:Tensor\n",
    "                 ):\n",
    "        super().__init__()\n",
    "    \n",
    "    #a = torch.rand((10,2))\n",
    "    #b = torch.rand((10,5))\n",
    "\n",
    "    def computeJointDistribution(self) -> Tensor:\n",
    "        joint = torch.rand((10,10))\n",
    "\n",
    "        for i in range(2):\n",
    "            for j in range(5):\n",
    "                    joint[:, i*5+j] = self.x[:, i]*self.y[:, j]\n",
    "\n",
    "        c = self.x.unsqueeze(1) @ self.y.unsqueeze(1)\n",
    "        \n",
    "        torch.reshape(c, self.a.shape)\n",
    "\n",
    "        # sprawdzić wyniki\n",
    "        #print(torch.allclose(c, joint))\n",
    "\n",
    "        return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6685b455",
   "metadata": {},
   "source": [
    "<h2>Estymacja średnich</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d288cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimation(nn.Module):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 triplets,\n",
    "                 feature_fn,\n",
    "                 feature_dm\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.triplets = triplets,\n",
    "        self.feature_fn = feature_fn,\n",
    "        self.feature_dm - feature_dm\n",
    "\n",
    "    def compute_tensor_mean(self) -> Tensor:\n",
    "        \"\"\"\n",
    "        Parametry:\n",
    "            triplets: array (x, y, z)\n",
    "            feature_fn: funckaj mapująca\n",
    "            feature_dim: wymiary D\n",
    "        \"\"\"\n",
    "        a = np.zeros((self.feature_dim, self.feature_dim, self.feature_dim))\n",
    "        \n",
    "        for (x, y, z) in self.triplets:\n",
    "            fx = self.feature_fn(x)\n",
    "            fy = self.feature_fn(y)\n",
    "            fz = self.feature_fn(z)\n",
    "            \n",
    "            outer = np.einsum(fx, fy, fz)\n",
    "            \n",
    "            a += outer\n",
    "\n",
    "        a /= len(self.triplets)  # Normalizacja na trójkach\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa0fa5",
   "metadata": {},
   "source": [
    "<h2>Estymacja warunkowa</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4a4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalEstimation(nn.Module):\n",
    "    def __init__(self, \n",
    "                 *,\n",
    "                 x_candidates,\n",
    "                 y,\n",
    "                 z,\n",
    "                 a,\n",
    "                 feature_fn) -> None:\n",
    "        super().__init__()\n",
    "        self.x_candidates = x_candidates,\n",
    "        self.y = y,\n",
    "        self.z = z,\n",
    "        self.a = a,\n",
    "        self.feature_fn - feature_fn\n",
    "\n",
    "    def conditional_score(self):\n",
    "\n",
    "        D = self.a.shape[0]\n",
    "        fy = self.feature_fn(self.y)\n",
    "        fz = self.feature_fn(self.z)\n",
    "\n",
    "        denominator = 0\n",
    "        for j in range(D):\n",
    "            for k in range(D):\n",
    "                denominator += self.fa[0, j, k] * fy[j] * fz[k]\n",
    "\n",
    "        scores = []\n",
    "        for x in self.x_candidates:\n",
    "            fx = self.feature_fn(x)\n",
    "            \n",
    "            score = 0\n",
    "            for i in range(D):\n",
    "                context_sum = 0\n",
    "                for j in range(D):\n",
    "                    for k in range(D):\n",
    "                        context_sum += self.a[i, j, k] * fy[j] * fz[k]\n",
    "                score += fx[i] * (context_sum / (denominator + 1e-8)) #uniknięcie dzielenia przez zero\n",
    "\n",
    "            scores.append(score)\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73556b28",
   "metadata": {},
   "source": [
    "<h2>Propagacja 1</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0552a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropagationEstimation(nn.Module):\n",
    "    def __init__(self, \n",
    "                 *, \n",
    "                 y, \n",
    "                 z, \n",
    "                 a, \n",
    "                 feature_fn):\n",
    "        super().__init__()\n",
    "        self.y = y,\n",
    "        self.z = z,\n",
    "        self.a = a,\n",
    "        self.feature_fn = feature_fn\n",
    "\n",
    "    def propagate_expectation(self):\n",
    "\n",
    "        fy = self.feature_fn(self.y)\n",
    "        fz = self.feature_fn(self.z)\n",
    "        D = fy.shape[0]\n",
    "\n",
    "        numerator = 0.0\n",
    "        denominator = 0.0\n",
    "        for j in range(D):\n",
    "            for k in range(D):\n",
    "                numerator += self.a[1, j, k] * fy[j] * fz[k]\n",
    "                denominator += self.a[0, j, k] * fy[j] * fz[k]\n",
    "\n",
    "        propagated = 0.5 + (1 / (2 * np.sqrt(3))) * (numerator / (denominator + 1e-8))\n",
    "        return propagated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db695a9",
   "metadata": {},
   "source": [
    "<h2>Entropia</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5228003",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropyAndMutualInformation(nn.Module):\n",
    "\n",
    "def approximate_entropy(activations):\n",
    "\n",
    "    # Normalizacja prawdopodobieństw funkcji aktywacji\n",
    "    probs = F.softmax(activations, dim=1)\n",
    "    entropy = -torch.sum(probs ** 2, dim=1).mean()\n",
    "    return entropy\n",
    "\n",
    "def approximate_mutual_information(act_X, act_Y):\n",
    "\n",
    "    # Normalizacja funkcji aktywacji\n",
    "    probs_X = F.softmax(act_X, dim=1)\n",
    "    probs_Y = F.softmax(act_Y, dim=1)\n",
    "    \n",
    "    joint_probs = torch.bmm(probs_X.unsqueeze(2), probs_Y.unsqueeze(1))\n",
    "    \n",
    "    mi = torch.sum(joint_probs ** 2, dim=(1,2)).mean()\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096dff88",
   "metadata": {},
   "source": [
    "<h2>Dynamicznie modyfikowany model za pomocą EMA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicEMA(nn.Module):\n",
    "    def __init__(self, x, y, z, ema_lambda) -> None:\n",
    "        self.x = x,\n",
    "        self.y = y,\n",
    "        self.z = z,\n",
    "        self.ema_lambda = ema_lambda\n",
    "\n",
    "    def EMAUpdateMethod(self):\n",
    "        def f_i(x): return x\n",
    "        def f_j(y): return y\n",
    "        def f_k(z): return z\n",
    "\n",
    "        update_tensor = torch.einsum('i,j,k->ijk', f_i(self.x), f_j(self.y), f_k(self.z))\n",
    "\n",
    "        # EMA updating values\n",
    "        a = (1 - self.ema_lambda) * a + self.ema_lambda * update_tensor\n",
    "        \n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c770ab",
   "metadata": {},
   "source": [
    "<h2>Optymizacja bazy</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d8e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseOptimization(nn.Module):\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 a, #tensor do optymalizacji\n",
    "                 ) -> None:\n",
    "        self. a = a\n",
    "\n",
    "    def optimization_early(self) -> Tensor:\n",
    "        M = self.a.reshape(len(self.a[0]), -1)\n",
    "\n",
    "        # Obliczenie SVD\n",
    "        U, S, Vh = torch.linalg.svd(M, full_matrices=False)\n",
    "\n",
    "        # Transformacja Bazy, tu przykładowa funkcja, do wymiany\n",
    "        def f_x(x):\n",
    "            return torch.sin(x * torch.linspace(0, 1, len(self.a[2])))\n",
    "\n",
    "        # nowa baza g_i(x) = sum_j v_ij * f_j(x)\n",
    "        def g_i(x, U):\n",
    "            f = f_x(x)\n",
    "            return torch.matmul(U.T, f)\n",
    "\n",
    "        # Step 4: Transformacja Tensora\n",
    "        new_a = torch.einsum('li,ljk->ijk', U.T, self.a)\n",
    "\n",
    "        return new_a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
